getwd()
str(str)
str(str)
str(ls)
set.seed(1)
test <- set.seed(3)
test
test <- set.seed(85)
test
rnorm(4)
a <- rnorm(4)
a
set.seed(8)
rnorm(4)
rnorm(14)
rnorm(10)
set.seed(10)
x <- rbinom(100,1,0.5)
e <- rnorm(100,0,2)
y <- 0.5 +2 * x + e
y
summary(y)
plot(x,y)
set.seed(1)
x <- rnorm(100)
x <- rnorm(100) <- 0.5 + 0.3 *x
long.mu <- 0.5 + 0.3 *x
y <- rpois(100,exp(long.mu))
summary(y)
plot(x,y)
sample(1:10,4)
system.time()
help(system.time())
help(system.time
)
sample.interval(10000)
summaryRprof()
by.total
set.seed(1)
rpois(5,2)
library(swirl)
swirl()
exit()
exit
quit()
swirl()
install.library("swirl")
install.packages("swirl")
install_from_swirl("Getting and Cleaning Data")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
group_by(cran)
?group_by
by_package<-group_by(cran,package)
by_package
summarize(mean(size),by_package)
summarize(mean(selec(cran,size)),by_package)
summarize(mean(select(cran,size)),by_package)
summarize(mean(tbl_df,by_package)
summarize(mean(tbl_df),by_package)
?summarize
group_by(package)%>%summarize(mean(tbl_df(package)))
group_by(package)%>%summarize(mean(tbl_df,package)
group_by(package)%>%summarize(mean(tbl_df,package))
group_by(package)%>%summarize(mean(tbl_df))
by_package%>%summarize(mean(tbl_df))
summarize(by_package,mean(size))
library(installr)
library(remotes)
install.packages("remotes")
install.packages("pdfLatex")
install.packages("MiKTeX")
ap <- available.packages()
"MikTex" %in% rownames(ap)
"PDFLaTex" %in% rownames(ap)
"pdflatex" %in% rownames(ap)
library(installr)
install.packages("MiKTeX", repos = "http://miktex.org/2.9/setup")
install.packages("latexpdf", dependencies=TRUE, repos=https://cran.r-project.org/package=latexpdf)
install.packages("latexpdf", dependencies=TRUE, repos=https://cran.r-project.org)
install.packages("latexpdf", dependencies=TRUE, repos='https://cran.r-project.org')
shiny::runApp('GitHub/Shiny_app/SilviaApp')
myCorpus = tm_map(myCorpus, removeNumbers)
library(tm)
library(wordcloud)
library(memoise)
library(shiny)
# The list of valid books
books <<- list("A Mid Summer Night's Dream" = "summer",
"The Merchant of Venice" = "merchant",
"Romeo and Juliet" = "romeo")
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
})
runApp('GitHub/Shiny_app/SilviaApp')
runApp('GitHub/Shiny_app/SilviaApp')
getwd()
setwd("C:/Users/silvi/OneDrive/Documents/GitHub/Shiny_app/SilviaApp")
runApp("app.R")
getwd()
runApp('appcheck.R')
runApp('others')
runApp()
runApp('others/app3.R')
rock
pressure
cars
datasets::ability.cov
airquality
head(airquality)
head(rock)
head(pressure)
head(cars)
runApp('others/app3.R')
runApp('others/app3.R')
runApp('others/app3.R')
runApp('others/app3.R')
runApp('others/app3.R')
euro
eurodist
EuStockMarkets
head(EuStockMarkets)
faithful
head(faithful)
head(
Indometh)
head(InsectSprays)
head(
JohnsonJohnson)
JohnsonJohnson
runApp('others/app3.R')
JohnsonJohnson
LifeCycleSavings
longley
runApp('others/app3.R')
pressure
runApp('others/app3.R')
runApp('others/app3.R')
sleep
ToothGrowth
UKgas
runApp('others/app3.R')
women
volcano
WWWusage
runApp('others/app3.R')
runApp('others/app3.R')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runApp('~/GitHub/Shiny_app/stockViz')
runExample("01hello")
runExample("01_hello")
runExample("01_hello")
runExample("08_html")
runExample("03_reactivity")
data(trees)
head(trees)
library(GGally)
install.packages("GGally")
ggpairs(data=trees, columns=1:3, title="trees data")
ggpairs(data=trees, columns=1:3, title="trees data")
library(GGally)
ggpairs(data=trees, columns=1:3, title="trees data")
fit_1 <- lm(Volume ~ Girth, data = trees)
fit_1
summary(fit_1)
Using Linear Regression for Predictive Modeling in R
linear-reg-r
Predictive models are extremely useful, when learning r language, for forecasting future outcomes and estimating metrics that are impractical to measure. For example, data scientists could use predictive models to forecast crop yields based on rainfall and temperature, or to determine whether patients with certain traits are more likely to react badly to a new medication. Before we talk about linear regression specifically, let’s remind ourselves what a typical data science workflow might look like. A lot of the time, we’ll start with a question we want to answer, and do something like the following:
Collect some data relevant to the problem (more is almost always better).
Clean, augment, and preprocess the data into a convenient form, if needed.
Conduct an exploratory analysis of the data to get a better sense of it.
Using what you find as a guide, construct a model of some aspect of the data.
Use the model to answer the question you started with, and validate your results.
Linear regression is one of the simplest and most common supervised machine learning algorithms that data scientists use for predictive modeling. In this post, we’ll use linear regression to build a model that predicts cherry tree volume from metrics that are much easier for folks who study trees to measure.
We’ll use R in this blog post to explore this data set and learn the basics of linear regression. If you’re new to learning the R language, we recommend our R Fundamentals and R Programming: Intermediate courses from our R Data Analyst path. It will also help to have some very basic statistics knowledge, but if you know what a mean and standard deviation are, you’ll be able to follow along. If you want to practice building the models and visualizations yourself, we’ll be using the following R packages:
data sets This package contains a wide variety of practice data sets. We’ll be using one of them, “trees”, to learn about building linear regression models.
ggplot2 We’ll use this popular data visualization package to build plots of our models.
GGally This package extends the functionality of ggplot2. We’ll be using it to create a plot matrix as part of our initial exploratory data visualization.
scatterplot3d We’ll use this package for visualizing more complex linear regression models with multiple predictors.
How do they measure tree volume, anyway?
The trees data set is included in base R’s datasets package, and it’s going to help us answer this question. Since we’re working with an existing (clean) data set, steps 1 and 2 above are already done, so we can skip right to some preliminary exploratory analysis in step 3. What does this data set look like?
data(trees) ## access the data from R’s datasets package
head(trees) ## look at the first several rows of the data
girth	height	volume
8.3	70	10.3
8.6	65	10.3
8.8	63	10.2
10.5	72	16.4
10.7	81	18.8
10.8	83	19.7
str(trees) ## look at the structure of the variables
$ Girth : num	8.3 8.6 8.8 10.5 10.7 10.8 11 11 11.1 11.2 …
$ Height: num	70 65 63 72 81 83 66 75 80 75 …
$ Volume: num	10.3 10.3 10.2 16.4 18.8 19.7 15.6 18.2 22.6 19.9 …
This data set consists of 31 observations of 3 numeric variables describing black cherry trees:
The trunk girth (in)
height (ft)
volume (ft3)
These metrics are useful information for foresters and scientists who study the ecology of trees. It’s fairly simple to measure tree heigh and girth using basic forestry tools, but measuring tree volume is a lot harder. If you don’t want to actually cut down and dismantle the tree, you have to resort to some technically challenging and time-consuming activities like climbing the tree and making precise measurements. It would be useful to be able to accurately predict tree volume from height and/or girth.
pic3
To decide whether we can make a predictive model, the first step is to see if there appears to be a relationship between our predictor and response variables (in this case girth, height, and volume). Let’s do some exploratory data visualization. We’ll use the ggpairs() function from the GGally package to create a plot matrix to see how the variables relate to one another.
ggpairs(data=trees, columns=1:3, title="trees data")
ggpairs The ggpairs() function gives us scatter plots for each variable combination, as well as density plots for each variable and the strength of correlations between variables.
If you’ve used ggplot2 before, this notation may look familiar: GGally is an extension of ggplot2 that provides a simple interface for creating some otherwise complicated figures like this one. As we look at the plots, we can start getting a sense of the data and asking questions. The correlation coefficients provide information about how close the variables are to having a relationship; the closer the correlation coefficient is to 1, the stronger the relationship is. The scatter plots let us visualize the relationships between pairs of variables. Scatter plots where points have a clear visual pattern (as opposed to looking like a shapeless cloud) indicate a stronger relationship.
Our questions: Which predictor variables seem related to the response variable? From looking at the ggpairs() output, girth definitely seems to be related to volume: the correlation coefficient is close to 1, and the points seem to have a linear pattern. There may be a relationship between height and volume, but it appears to be a weaker one: the correlation coefficient is smaller, and the points in the scatter plot are more dispersed. What is the shape of the relationship between the variables?
The relationship appears to be linear; from the scatter plot, we can see that the tree volume increases consistently as the tree girth increases. Is the relationship strong, or is noise in the data swamping the signal? The relationship between height and volume isn’t as clear, but the relationship between girth and volume seems strong. Now that we have a decent overall grasp of the data, we can move on to step 4 and do some predictive modeling.
Forming a hypothesis
A hypothesis is an educated guess about what we think is going on with our data. In this case, let’s hypothesize that cherry tree girth and volume are related. Every hypothesis we form has an opposite: the “null hypothesis” (H0). Here, our null hypothesis is that girth and volume aren’t related. In statistics, the null hypothesis is the one we use our data to support or reject; we can’t ever say that we “prove” a hypothesis. We call the hypothesis that girth and volume are related our “alternative” hypothesis (Ha). To summarize: H0 : There is no relationship between girth and volume Ha: There is some relationship between girth and volume Our linear regression model is what we will use to test our hypothesis. If we find strong enough evidence to reject H0, we can then use the model to predict cherry tree volume from girth.
Building blocks of a linear regression model
Linear regression describes the relationship between a response variable (or dependent variable) of interest and one or more predictor (or independent) variables. It helps us to separate the signal (what we can learn about the response variable from the predictor variable) from the noise (what we can’t learn about the response variable from the predictor variable). We’ll dig deeper into how the model does this as we move along.
pic5
Let’s dive right in and build a linear model relating tree volume to girth. R makes this straightforward with the base function lm().
fit_1 <- lm(Volume ~ Girth, data = trees)
The lm() function fits a line to our data that is as close as possible to all 31 of our observations. More specifically, it fits the line in such a way that the sum of the squared difference between the points and the line is minimized; this method is known as “minimizing least squares.” Even when a linear regression model fits data very well, the fit isn’t perfect. The distances between our observations and their model-predicted value are called residuals.
pic6
Mathematically, can we write the equation for linear regression as: Y ≈ β0 + β1X + ε
The Y and X variables are the response and predictor variables from our data that we are relating to eachother
β0 is the model coefficient that represents the model intercept, or where it crosses the y axis
β1 is the model coefficient that represents the model slope, the number that gives information about the steepness of the line and its direction (positive or negative)
ε is the error term that encompasses variability we cannot capture in the model (what X cannot tell us about Y)
In the case of our example: Tree Volume ≈ Intercept + Slope(Tree Girth) + Error pic7
The lm() function estimates the intercept and slope coefficients for the linear model that it has fit to our data. With a model in hand, we can move on to step 5, bearing in mind that we still have some work to do to validate the idea that this model is actually an appropriate fit for the data.
Can we use this model to make predictions?
Whether we can use our model to make predictions will depend on:
Whether we can reject the null hypothesis that there is no relationship between our variables.
Whether the model is a good fit for our data.
Let’s call the output of our model using summary(). The model output will provide us with the information we need to test our hypothesis and assess how well the model fits our data.
summary(fit_1)
lm_output-1 Let’s walk through the output to answer each of these questions.
Is the hypothesis supported?
Coefficients: Estimate and Std. Error:
The intercept in our example is the expected tree volume if the value of girth was zero. Of course we cannot have a tree with negative volume, but more on that later.
The slope in our example is the effect of tree girth on tree volume. We see that for each additional inch of girth, the tree volume increases by 5.0659 ft3.
The coefficient standard errors tell us the average variation of the estimated coefficients from the actual average of our response variable.
t value:
This is a test statistic that measures how many standard deviations the estimated coefficient is from zero.
Pr(>|t|):
This number is the p-value, defined as the probability of observing any value equal or larger than t if H0 is true. The larger the t statistic, the smaller the p-value. Generally, we use 0.05 as the cutoff for significance; when p-values are smaller than 0.05, we reject H0.
We can reject the null hypothesis in favor of believing there to be a relationship between tree width and volume.
How well does the model fit the data?
Residuals:
This section of the output provides us with a summary of the residuals (recall that these are the distances between our observation and the model), which tells us something about how well our model fit our data. The residuals should have a pretty symmetrical distribution around zero. Generally, we’re looking for the residuals to be normally distributed around zero (i.e. a bell curve distribution), but the important thing is that there’s no visually obvious pattern to them, which would indicate that a linear model is not appropriate for the data.
We can make a histogram to visualize this using ggplot2.
ggplot(data=trees, aes(fit_1$residuals)) +
geom_histogram(binwidth = 1, color = "black", fill = "purple4") +
theme(panel.background = element_rect(fill = "white"),
axis.line.x=element_line(),
axis.line.y=element_line()) +
ggtitle("Histogram for Model Residuals")
hist-1
Our residuals look pretty symmetrical around 0, suggesting that our model fits the data well. Residual standard error:
This term represents the average amount that our response variable measurements deviate from the fitted linear model (the model error term).
Degrees of freedom (DoF):
Discussion of degrees of freedom can become rather technical. For the purposes of this post, it is sufficient to think of them as the number of independent pieces of information that were used to calculate an estimate. DoF are related to, but not the same as, the number of measurements.
Multiple R-squared:
The R2 value is a measure of how close our data are to the linear regression model. R2 values are always between 0 and 1; numbers closer to 1 represent well-fitting models. R2 always increases as more variables are included in the model, and so adjusted R2 is included to account for the number of independent variables used to make the model.
F statistic:
This test statistic tells us if there is a relationship between the dependent and independent variables we are testing. Generally, a large F indicates a stronger relationship.
p-value:
This p-value is associated with the F statistic, and is used to interpret the significance for the whole model fit to our data.
Let’s have a look at our model fitted to our data for width and volume. We can do this by using ggplot() to fit a linear model to a scatter plot of our data:
ggplot(data = trees, aes(x = Girth, y = Volume)) +
geom_point() +
stat_smooth(method = "lm", col = "dodgerblue3") +
theme(panel.background = element_rect(fill = "white"),
axis.line.x=element_line(),
axis.line.y=element_line()) +
ggtitle("Linear Model Fitted to Data")
predict(fit_1, data.frame(Girth = 18.2))
predict(fit_1, data.frame(Girth = 18.2))
fit_2 <- lm(Volume ~ Girth + Height, data = trees)
summary(fit_2)
Since we have two predictor variables in this model, we need a third dimension to visualize it. We can create a nice 3d scatter plot using the package scatterplot3d:
Girth <- seq(9,21, by=0.5) ## make a girth vector
Height <- seq(60,90, by=0.5) ## make a height vector
pred_grid <- expand.grid(Girth = Girth, Height = Height)
pred_grid$Volume2 <-predict(fit_2, new = pred_grid)
fit_2_sp <- scatterplot3d(pred_grid$Girth, pred_grid$Height, pred_grid$Volume2, angle = 60, color = "dodgerblue", pch = 1, ylab = "Hight (ft)", xlab = "Girth (in)", zlab = "Volume (ft3)" )
install.packages("scatterplot3d")
library("scatterplot3d")
fit_2_sp <- scatterplot3d(pred_grid$Girth, pred_grid$Height, pred_grid$Volume2, angle = 60, color = "dodgerblue", pch = 1, ylab = "Hight (ft)", xlab = "Girth (in)", zlab = "Volume (ft3)" )
fit_2_sp$points3d(trees$Girth, trees$Height, trees$Volume, pch=16)
predict(fit_2, data.frame(Girth = 18.2, Height = 72))
fit_3 <- lm(Volume ~ Girth * Height, data = trees)
summary(fit_3)
Girth <- seq(9,21, by=0.5)
Height <- seq(60,90, by=0.5)
pred_grid <- expand.grid(Girth = Girth, Height = Height)
pred_grid$Volume3 <-predict(fit_3, new = pred_grid)
fit_3_sp <- scatterplot3d(pred_grid$Girth, pred_grid$Height, pred_grid$Volume3, angle = 60, color = "dodgerblue", pch = 1, ylab = "Hight (ft)", xlab = "Girth (in)", zlab = "Volume (ft3)")
fit_3_sp$points3d(trees$Girth, trees$Height, trees$Volume, pch=16)
predict(fit_3, data.frame(Girth = 18.2, Height = 72))
colnames(diamonds)
colnames(trees)
max(diamonds$carat)
min(diamonds$carat)
min(diamonds$cut)
min(diamonds$color)
diamonds[,c(1:4,7)]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
min(trees$Girth)
max(trees$Girth)
max(trees$Height)
min(trees$Height)
runApp()
head(trees)
trees$Volume[c(,trees$Girth=8.3)]
trees$Volume[trees$Girth=8.3]
trees$Volume[,c(trees$Girth=8.3)]
trees$Volume[,ctrees$Girth=8.3]
trees$Volume[,trees$Girth=8.3]
subset(trees, trees$Girth=8.3)
data %>% filter(trees$Girth=8.3)
data %>% filter(trees$Girth==8.3)
data %>% filter(trees$Girth>8.3)
trees %>% filter(trees$Girth>8.3)
trees %>% filter(trees$Girth>=8.3)
trees %>% filter(trees$Girth>=8.3 | trees$Height=70)
trees %>% filter(trees$Girth>=8.3 | trees$Height>=70)
trees %>% filter(trees$Girth==8.3 | trees$Height==70)
trees$Volume %>% filter(trees$Girth==8.3 | trees$Height==70)
trees[3] %>% filter(trees$Girth==8.3 | trees$Height==70)
runApp()
runApp()
runApp()
fit_3 <- lm(Volume ~ Girth * Height, data = trees)
Girth <- seq(9,21, by=0.5)
Height <- seq(60,90, by=0.5)
pred_grid <- expand.grid(Girth = Girth, Height = Height)
pred_grid$Volume3 <-predict(fit_3, new = pred_grid)
fit_3_sp <- scatterplot3d(pred_grid$Girth, pred_grid$Height, pred_grid$Volume3, angle = 60, color = "dodgerblue", pch = 1, ylab = "Hight (ft)", xlab = "Girth (in)", zlab = "Volume (ft3)")
fit_3_sp$points3d(trees$Girth, trees$Height, trees$Volume, pch=16)
predict(fit_3, data.frame(Girth = 18.2, Height = 72))
runApp()
runApp()
runApp()
runApp()
